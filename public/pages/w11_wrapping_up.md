---
layout: page
---


W11 Wrapping Up
===============

I prepared a "W11 Wrapping Up.ipynb" file containing the content of this week.
The first two "parts" are presented in the videos I uploaded.

As you know, in this week I had planned to speak a little about Language Models.
I felt, however, that everything that I had to say was already said, and
whatever was "left" was only going to be a lot of math, that I didn't feel would
be useful for you. So I changed my mind and created this "Wrapping Up" content.
The goals are the following:

* To explore a little more these word vectors (that everyone keeps using and
  talking about these days)
* To show you one way that you can just "access" the word vectors, without
  having to train a Machine Learning model, or deal with too many complications.
  In our case, we will use a Python library called Flair.
* To show you some of the "limitations" of these vectors, and try to help you
  get some intuition of what they are doing.

Because this class is so "unorthodox", almost none of this will appear in the
exam. There are only two things that I want you to know from this class (that
may appear in the exam):

* Why BERT vectors are called "contextual" word vectors.
* Word vectors do not represent synonymy (at least not in the way we are used
  to thing about it)

Finally, also because this class is so "different", I don't really intend to
make a Quiz for it. So, instead, I'd like to ask you to answer the feedback
questionnaire about the course. It will be anonymous... you can be as harsh as
you want =)

I hope this course was useful. Thank you for your participation. In the next
week there will only be a Q&A, and then we have the exam.

