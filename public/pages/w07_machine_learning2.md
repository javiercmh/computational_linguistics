---
layout: page
---


W7 Machine Learning (part 2)
============================

On the Previous Week
--------------------

In the previous week, when I spoke about Classification, I felt that I didn't
manage to make it so clear what I meant with the existence of a function "g"
that we were trying to approximate with our function "f". I was trying to refer
(and I didn't really use this wording because I really couldn't find it before)
about the "Manifold Hypothesis". The idea is that the function "g" is "out
there", and we want to find it. We also assume that it is continuous. I found a
video that I think makes it quite clear what this "manifold" is. I would like
you to watch it:

[https://www.youtube.com/watch?v=BePQBWPnYuE](https://www.youtube.com/watch?v=BePQBWPnYuE)

Gradient Descent
----------------

Please watch these videos on Neural Networks from the 3Blue1Brown. I think it
will be SUPER USEFUL to sediment the ideas discussed this week, and also to
prepare you for the topic of next week.

What is a Neural Network:
[https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=1](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=1)

Gradient Descent:
[https://www.youtube.com/watch?v=IHZwWFHWa-w&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=2](https://www.youtube.com/watch?v=IHZwWFHWa-w&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=2)

I honestly suggest you to watch this both before and after my videos of this
week. If you watch before, it will help you to build some "expectations" about
the kinds of things you'll learn about (and it will help you A LOT with this
week's topic). If you watch after, it will work as a super good example of how
the things you learnt about are applied.

Dataset Splits / Hyperparameters
--------------------------------

If you have difficulties understanding the first video of this week (on kNN and
Dataset Splits), you might want to watch an alternative explanation: the Andrej
Karpathy class on the topic. It is a little more mathy, but it is really good,
and the entire content of my video is also present there:

[https://www.youtube.com/watch?v=8inugqhkfve&list=plkt2usq6rbvctenovbg1tpcc7oqi31alc&index=3&t=0s](https://www.youtube.com/watch?v=8inugqhkfve&list=plkt2usq6rbvctenovbg1tpcc7oqi31alc&index=3&t=0s)

(in fact, if you have interest in learning about ML, these classes are a great
resource)


Regression
----------

You'll find a jupyter notebook called "W7 Regression.ipynb" in the downloads
folder. This is what I used during my videos.


Logistic Regression
-------------------

(to be read after watching video 5)

Between the videos 5 and 6, I would like you to read the part on Logistic
Regression in the jupyter notebook "W7 Rgression,ipynb", that is in the
downloads folder.

I found that it didn't really make sense to explain this in video, because I
feel that it is very much the same. That section is quite inspired on some
other materials that are also linked there. If you have troubles understanding
it, you may want to take a look at those other materials.

(of course, you can also always post questions in the forum)


